\documentclass[../report.tex]{subfiles}

\begin{document}

\textcite{benamou2018entropy} propose a discretization of \eqref{eq:EntropyLagrangianProblem} obtained by connecting the marginals through a multimarginal OT problem.

However, the paper does not go into detail about handling spatial discretization on a finite domain and efficient computation of the marginals: we will clarify these points in the later subsections.


\subsection{Time discretization: multimarginal Sinkhorn}\label{sec:MMOT}

Let $N$ be the number of discrete steps for the time discretization of the problem and $t_k = kh$ be the discrete times with time step $h=T/N$.

Denote $R^N = R_{t_0,\ldots,t_N}$ and the marginals $\mu_k \in \calP_2(\Omega)$, and $\Pi(\mu_0, \ldots, \mu_N)$ is the usual constraint set for transport. \textcite{benamou2018entropy} show that the mean-field game translates to the following convex optimization problem:
\begin{equation}\label{eq:TimeDiscretePrimal}
\begin{aligned}
&\inf_{\gamma \in \calP(\Omega^{N+1})}
H(\gamma | R^N) + \imath_{\rho_0}(\rho_0) + \sum_{k=1}^{N-1} F(\rho_k) + G(\rho_N) \\
\suchthat\ &\pi^k_\#\gamma = \rho_k, \quad 0\leq k\leq N
\end{aligned}
\end{equation}
where $\imath_{\rho_0}(\mu) = +\infty$ if $\mu\neq \rho_0$ and $0$ otherwise is the convex indicatrix of the measure $\rho_0$. This is a generalized multimarginal optimal transport problem.

\textcite{benamou2018entropy} provide the corresponding dual problem involving the convex conjugates:
\begin{equation}\label{eq:TimeDiscreteDual}
\sup_u
\int_{\Omega^{N+1}} \left(1-\exp\left(\oplus_{k=0}^N u_k\right)\right) \,dR^N
-\imath_{\rho_0}^*(-u_0) - \sum_{k=1}^{N-1} F^*(-u_k) - G^*(-u_N)
\end{equation}
where the supremum is taken over $u = (u_0,\ldots,u_N) \in L^\infty(\Omega)^{N+1}$. The optimum $u^*$ of \eqref{eq:TimeDiscreteDual} is linked to the optimal transport plan $\gamma^*$ of \eqref{eq:TimeDiscretePrimal} by
\begin{equation}
	\gamma^* = e^{\oplus_{k=0}^N u^*_k} R^N
\end{equation}
The optimum satisfies a fixed-point condition which can be solved numerically using generalized Sinkhorn iterations. We rewrite it more explicitly with slightly different notations:

\begin{prop}\label{algo:Sinkhorn}
	Denote for $k=0,\ldots,N$ and $(a_j)_{j}$
	\[
	\calI^a_k(x_k) = 
	\int_{\Omega^N}
	\prod_{j\neq k} a_j(x_j)
	R^N(x_0,\ldots,x_N)\,d\boldsymbol{x}_{-k}
	\]
	the marginalization of the $a_j,j\neq k$ with respect to $R^N$ without variable $x_k$.
	For convenience we use the shorthands
	\begin{align*}
	\calI_k^* = \calI_k^{a^*} \quad \text{and}\quad \calI_k^{(n)} = \calI_k\left((a^{(n+1)}_j)_{j<k},
	(a^{(n)}_j)_{j>k}\right)
	\end{align*}
	for the $n$th iterate, where we denote $a_j = \exp(u_j)$.
	
	Using duality, we have that the optimum of \eqref{eq:TimeDiscreteDual} satisfies the fixed-point condition
	\begin{equation*}\bluefont\left\{
	\begin{aligned}
		a^*_0 &= \frac{\rho_0}{\calI_0^*}  \\
		a^*_k &= \frac{\prox_{hF_k}^{\KL}(\calI_k^*)}{\calI_k^*}, \quad 1\leq k < N  \\
		a^*_N &= \frac{
			\prox_{G}^{\KL}(\calI_N^*)}{\calI_N^*
		}
	\end{aligned}\right.
	\end{equation*}
	where $\prox_F^{\KL}(z) = \argmin_{s} F(s) + \KL(s|z)$ is the $\KL$-proximal operator.
	This fixed point condition can be solved using Sinkhorn iterates: these iterates $a_k^{(n)}$ are updated as
	\begin{equation}
	{\bluefont
	a_k^{(n+1)} = \exp\left(u^{(n+1)}_k\right) =
	\frac{
		\prox_{F_k}^{\KL}(\calI_k^{(n)})
	}{\calI_k^{(n)}}}
	\end{equation}
\end{prop}




\subsection{Spatial discretization}\label{sec:PartialDiscret}

For full numerical implementation, all measures are replaced by multi-dimensional arrays representing histograms over a grid of size $M = \prod_k N_k$ of points in $\RR^d$.

\paragraph{Handling finite domains and obstacles}\label{sec:Finitedomainobstacles}
The theory introduced by the paper has some limitations: for instance it only considers MFGs with domain $\RR^d$. What happens when our domain is some $\Omega \subsetneq \RR^d$, for instance a finite set with holes and obstacles? The standard heat kernel $\bfP$ is inadequate in that case and the appropriate Wiener measure on the space of trajectories $\calX$ changes.

\textcite{benamou:hal-01295299} circumvent the problem by assuming $\Omega$ is a convex domain and imposing a no-mass constraint $\rho = 0$ on a subset of obstacles $\mathscr{O} \subset \Omega$.

\paragraph{Sum-product algorithm.} Denoting $\bfR \in \RR^{M^N}$ the discretization of $R^N_\epsilon$, integration of $a_0,\ldots,a_N\in\RR^M$ with respect to the Wiener marginal $R^N_\epsilon$ translates to
\[
	\bfR[a_0, \ldots, a_N] =
	\sum_{i_0,\ldots,i_N} \bfR_{i_0,\ldots,i_N}\prod_{k=0}^N a_{i_k}
\]
A naive implementation computes the sum in time $\calO(NM^N)$: this is a well known problem is computational statistics and graphical models, and an efficient way of dealing with it is by exploiting the structure of the kernel $\bfR$. This aspect is not discussed in the paper by \textcite{benamou:hal-01295299}: for the sake of completeness and clarity, we introduce the following algebraic result and deduce an appropriate algorithm.

Recall the expression of the Wiener marginal $R^N$ \cref{eq:NMarginWienerMeasure}: it suggests the marginals $\mu_0,\ldots,\mu_N$ only communicate as in an undirected chain. We have the following result:
\begin{prop}[Efficient convolution to $\bfR$]\label{prop:efficientConvol}
	The kernel $\bfR$ can be factorized as 
	\[
		\bfR_{i_0,\ldots,i_N} = \prod_{k=0}^{N-1} \bfP_{i_k,i_{k+1}}
	\]
	where $\bfP$ is the discrete heat kernel on the grid. The partial convolution $\calI^a_k$ (leaving the $k$th component out) can now be written as
	\begin{equation}
	{\bluefont
		\calI_k^a = \bfR[(a_j)_{j\neq k}] =
		\mathbf{A} \odot \mathbf{B}
	}
	\end{equation}
	where $\mathbf{A} = \bfP^T (a_{k-1} \odot \bfP^T(a_{k-2} \odot \cdots))$ and $\mathbf{B} = \bfP (a_{k+1} \odot \bfP (a_{k+2}\odot \cdots))$.
\end{prop} This leads to the efficient message-passing \cref{algo:EfficientIntegral}.
\begin{algorithm}[h]
\caption{Efficient computation of $\calI_k$.}\label{algo:EfficientIntegral}
\KwIn{Base heat kernel $\bfP$, index $k$, vectors $(a_j)_{j\neq k}$}
$\mathbf{A} \leftarrow \mathds{1}$\;
\For{$i=0$ to $k-1$}{
	$\mathbf{A} \leftarrow \bfP^T(a_i \odot\mathbf{A})$\;
}
$\mathbf{B} \leftarrow \mathds{1}$\;
\For{$i=N$ down to $k+1$}{
	$\mathbf{B} \leftarrow \bfP(a_i \odot\mathbf{B})$\;
}
\Return{$\mathbf{A}\odot\mathbf{B}$}\;
\end{algorithm}

The computational complexity of \cref{algo:EfficientIntegral} depends on how efficiently we can compute the convolution $\mathbf{P}u$. The naive matrix product performs in time $\calO(M^3)$, leading to total complexity $\calO(NM^3)$ which can still be very high. For separable heat kernels $\bfP$, such as on a rectangular grid, factorizing $\bfP u$ as two smaller convolutions can net considerable speedups \parencite[see][p.~74]{peyr2018computational} and reduce complexity to $\calO(dN\sqrt[d]{M}^3)$.



\end{document}